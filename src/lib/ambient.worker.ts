
/**
 * @file AuraGroove Ambient Music Worker
 *
 * This worker operates on a microservice-style architecture.
 * It is the "Sound Engine", responsible for both composing and rendering audio.
 */
import type { DrumNote, SynthNote, WorkerCommand, WorkerSettings, DrumSampleName } from '@/types/music';

// --- 1. PatternProvider (The Music Sheet Library) ---
const PatternProvider = {
    drumPatterns: {
        ambient_beat: [
            { sample: 'kick' as DrumSampleName, time: 0, velocity: 1.0 },
            { sample: 'hat' as DrumSampleName, time: 0.5, velocity: 0.3 },
            { sample: 'snare' as DrumSampleName, time: 1.0, velocity: 0.8 },
            { sample: 'hat' as DrumSampleName, time: 1.5, velocity: 0.3 },
            { sample: 'kick' as DrumSampleName, time: 2.0, velocity: 0.9 },
            { sample: 'hat' as DrumSampleName, time: 2.5, velocity: 0.3 },
            { sample: 'snare' as DrumSampleName, time: 3.0, velocity: 0.7 },
            { sample: 'hat' as DrumSampleName, time: 3.5, velocity: 0.3 },
        ],
        composer: [], // This will be dynamically generated by the EvolutionEngine
        none: []
    },
    getDrumPattern(name: string): DrumNote[] {
        return this.drumPatterns[name as keyof typeof this.drumPatterns] || [];
    },
};

// --- 2. Instrument Generators (The Composers) ---
class DrumGenerator {
    static createScore(patternName: string, barNumber: number, settings: { volume: number }): DrumNote[] {
        if (patternName === 'none') return [];
        const pattern = PatternProvider.getDrumPattern(patternName);
        let score = [...pattern];

        // Add a crash cymbal on the first beat of every 4th bar for ambient_beat
        if (patternName === 'ambient_beat' && barNumber % 4 === 0) {
            score = score.filter(note => note.time !== 0);
            score.push({ sample: 'crash', time: 0, velocity: 0.8 });
        }
        
        return score.map(note => ({...note, velocity: note.velocity * settings.volume}));
    }
}

class EvolutionEngine {
    generateDrumScore(bar: number, settings: {volume: number}): DrumNote[] {
         if (bar % 2 === 0) {
            return [
                { sample: 'kick', time: 0, velocity: 1.0 * settings.volume },
                { sample: 'hat', time: 1, velocity: 0.4 * settings.volume },
                { sample: 'snare', time: 2, velocity: 0.8 * settings.volume },
                { sample: 'hat', time: 3, velocity: 0.4 * settings.volume },
            ];
         }
         return [
                { sample: 'kick', time: 0, velocity: 1.0 * settings.volume },
                { sample: 'hat', time: 1.5, velocity: 0.3 * settings.volume },
                { sample: 'kick', time: 2, velocity: 0.9 * settings.volume },
                { sample: 'snare', time: 3, velocity: 0.7 * settings.volume },
         ]
    }
    
    generateAccompanimentScore(bar: number, settings: WorkerSettings): SynthNote[] {
        const isAccompanimentEnabled = settings.instrumentSettings?.accompaniment?.name !== 'none';
        if (!isAccompanimentEnabled) return [];

        const volume = settings.instrumentSettings?.accompaniment?.volume ?? 0.7;

        return [
            {
                note: ['C4', 'E4', 'G4', 'B4'],
                duration: 4, // in beats
                time: 0, // in beats
                velocity: 0.6 * volume,
            }
        ];
    }
}

// --- 3. SampleBank (Decoded Audio Storage) ---
const SampleBank = {
    samples: {} as Record<string, Float32Array>,
    isInitialized: false,

    async init(samples: Record<string, ArrayBuffer>, sampleRate: number) {
        const tempAudioContext = new OfflineAudioContext(1, 1, sampleRate);
        for (const key in samples) {
            if (samples[key] && samples[key].byteLength > 0) {
                try {
                    const audioBuffer = await tempAudioContext.decodeAudioData(samples[key].slice(0));
                    this.samples[key] = audioBuffer.getChannelData(0);
                } catch(e) {
                    self.postMessage({ type: 'error', error: `Failed to decode sample ${key}: ${e instanceof Error ? e.message : String(e)}` });
                }
            }
        }
        this.isInitialized = true;
        console.log("[WORKER_TRACE] SampleBank Initialized with samples:", Object.keys(this.samples));
    },

    getSample(name: string): Float32Array | undefined {
        return this.samples[name];
    }
};

// --- 4. AudioRenderer (The Sound Engine) ---
const AudioRenderer = {
    render(drumScore: DrumNote[], settings: { duration: number, sampleRate: number, secondsPerBeat: number }): Float32Array {
        const totalSamples = Math.floor(settings.duration * settings.sampleRate);
        const chunk = new Float32Array(totalSamples).fill(0);

        for (const note of drumScore) {
            const sampleData = SampleBank.getSample(note.sample);
            if (!sampleData) continue;
            
            const startSample = Math.floor(note.time * settings.secondsPerBeat * settings.sampleRate);

            for (let i = 0; i < sampleData.length; i++) {
                if (startSample + i < chunk.length) {
                    chunk[startSample + i] += sampleData[i] * note.velocity;
                }
            }
        }
        
        // Basic clipping prevention
        for (let i = 0; i < totalSamples; i++) {
            chunk[i] = Math.max(-1, Math.min(1, chunk[i]));
        }

        return chunk;
    }
};

// --- 5. Scheduler (The Conductor) ---
const Scheduler = {
    loopId: null as any,
    isRunning: false,
    barCount: 0,
    
    // Settings from main thread
    settings: {
        bpm: 120,
        score: 'evolve',
        drumSettings: { pattern: 'none', volume: 0.7, enabled: true },
        instrumentSettings: { accompaniment: { name: 'synthesizer', volume: 0.7 } },
    } as WorkerSettings,
    sampleRate: 44100,

    evolutionEngine: new EvolutionEngine(),

    // Calculated properties
    get beatsPerBar() { return 4; },
    get secondsPerBeat() { return 60 / this.settings.bpm; },
    get barDuration() { return this.beatsPerBar * this.secondsPerBeat; },

    start(data: WorkerSettings) {
        if (this.isRunning) this.stop();
        this.updateSettings(data);
        this.barCount = 0;
        this.isRunning = true;
        
        this.tick(); // Schedule first tick
        this.loopId = setInterval(() => this.tick(), this.barDuration * 1000);
        self.postMessage({ type: 'started' });
    },

    stop() {
        if (!this.isRunning) return;
        clearInterval(this.loopId);
        this.loopId = null;
        this.isRunning = false;
        self.postMessage({ type: 'stopped' });
    },
    
    updateSettings(newSettings: Partial<WorkerSettings>) {
        if (newSettings.drumSettings) this.settings.drumSettings = { ...this.settings.drumSettings, ...newSettings.drumSettings };
        if (newSettings.instrumentSettings) this.settings.instrumentSettings = { ...this.settings.instrumentSettings, ...newSettings.instrumentSettings };
        if (newSettings.bpm) this.settings.bpm = newSettings.bpm;
        if (newSettings.score) this.settings.score = newSettings.score;
    },

    tick() {
        if (!this.isRunning || !SampleBank.isInitialized) return;

        let drumScore: DrumNote[] = [];

        if (this.settings.drumSettings.enabled) {
             if (this.settings.drumSettings.pattern === 'composer') {
                drumScore = this.evolutionEngine.generateDrumScore(this.barCount, this.settings.drumSettings);
            } else {
                 drumScore = DrumGenerator.createScore(this.settings.drumSettings.pattern, this.barCount, this.settings.drumSettings);
            }
        }
        
        // Note: Accompaniment rendering not implemented yet. This first step focuses on drums.
        // const accompanimentScore = this.evolutionEngine.generateAccompanimentScore(this.barCount, this.settings);

        const audioChunk = AudioRenderer.render(drumScore, {
            duration: this.barDuration,
            sampleRate: this.sampleRate,
            secondsPerBeat: this.secondsPerBeat
        });
        
        const messageData = {
            chunk: audioChunk,
            startTime: 0, // This will be handled by the main thread's AudioPlayer queue
            duration: this.barDuration,
        };

        self.postMessage({
            type: 'audio_chunk',
            data: messageData
        }, [audioChunk.buffer]);

        this.barCount++;
    }
};


// --- MessageBus (The entry point) ---
self.onmessage = async (event: MessageEvent<WorkerCommand>) => {
    const { command, data } = event.data;

    try {
        switch (command) {
            case 'init':
                Scheduler.sampleRate = data.sampleRate;
                await SampleBank.init(data.samples, data.sampleRate);
                break;
            case 'start':
                Scheduler.start(data);
                break;
            case 'stop':
                Scheduler.stop();
                break;
            case 'update_settings':
                 Scheduler.updateSettings(data);
                break;
        }
    } catch (e) {
        self.postMessage({ type: 'error', error: e instanceof Error ? e.message : String(e) });
    }
};
