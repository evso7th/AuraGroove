Суть проблемы
Ты используешь Tone.js с несколькими моносинтезаторами (в пулах), и всё работает хорошо на ПК, но на мобильных устройствах (особенно бюджетных) возникают хрипы и заикания.
Причина:
* Весь аудиопроцессинг в Web Audio API выполняется в основном потоке (main thread), даже если вы создаёте несколько AudioContext — они всё равно под капотом используют один общий аудиодвижок (в Chrome, Safari и др.).
* Несмотря на попытки разделить контексты или использовать WebView — всё равно аудио микшируется в одном потоке рендеринга, и нагрузка от 6 синтезаторов перегружает CPU.
* Веб-воркеры не имеют прямого доступа к AudioContext, но есть AudioWorklet, который именно для этого и создан.
✅ Правильное решение: AudioWorklet + OffscreenCanvas (опционально) + декомпозиция синтеза
Тебе нужно вынести часть синтеза или микширования из основного потока. Но поскольку AudioContext нельзя использовать в воркере напрямую, единственный способ — использовать AudioWorklet.
AudioWorklet — это специальный тип воркера, который работает внутри аудиопотока, с низкой задержкой и высокой производительностью, и может генерировать или обрабатывать звук параллельно основному потоку. 
 &5;L:  0745;8BL =03@C7:C <564C =5A:>;L:8<8 =57028A8<K<8 0C48>?@>F5AA0<8
Но важно понимать: в браузере всё равно только один AudioContext, но AudioWorklet позволяет выполнять вычисления в другом потоке (аудиопотоке), что снижает нагрузку на main thread.
✅ Решение: Использовать AudioWorklet для частичного синтеза или предварительного рендеринга
Вариант 1: AudioWorklet как «удалённый» синтезатор
Генерация звука происходит внутри AudioWorklet, а не в Tone.js. 
Как это работает:
1. Ты создаёшь AudioWorkletProcessor, который генерирует звук (например, простой синтезатор).
2. Каждый такой процессор — это отдельный голос.
3. Управляешь им из main thread через AudioWorkletNode (передаёшь параметры: ноты, огибающие и т.п. через port.postMessage).
4. Такой подход снимает нагрузку с main thread, потому что генерация сигнала происходит в аудиопотоке, а не в JS-потоке.
Плюсы:
* Низкая задержка
* Высокая производительность
* Можно создать 6 AudioWorkletNode, каждый — отдельный синтезатор
Минусы:
* Нужно писать свой синтезатор на WebAssembly или вручную на JS (в process()).
* Нет прямой интеграции с Tone.js.
⚠️ Но: ты можешь оставить дирижирование в Tone.js, а звук генерировать в AudioWorklet. 
Вариант 2: Tone.js + AudioWorkletNode для микширования или предварительного рендеринга
Использовать Tone.js как есть, но рендерить часть инструментов в offscreen и проигрывать как AudioBufferSourceNode. 
Но это не подходит для реального времени, если всё генерируется динамически.
Вариант 3: Разделить синтезаторы на группы и рендерить каждую группу в отдельный OfflineAudioContext → кэшировать в буфер → проигрывать через AudioBufferSourceNode
Это не реальное время, но может помочь, если у тебя есть повторяющиеся паттерны. 
Не подходит, если всё генерируется динамически.
✅ Рекомендуемое решение: AudioWorklet-based синтезаторы + Tone.js как дирижёр
Архитектура:
* Main thread: Tone.js как дирижёр — управляет таймингом, посылает команды.
* AudioWorklet: 6 независимых AudioWorkletNode, каждый — моносинтезатор.
* Каждый AudioWorkletNode получает сообщения: "play C4", "release", "set attack=0.1" и т.д.
* Звук генерируется внутри AudioWorklet, CPU нагрузка снижается.
' 0: @50;87>20BL:
1. Создай synth-processor.js (для AudioWorklet)
js
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
⌄
⌄
⌄
⌄
⌄
⌄
⌄
⌄
⌄
// synth-processor.js
class SynthProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.phase = 0;
    this.frequency = 0;
    this.isActive = false;
    this.attack = 0.01;
    this.release = 0.1;
    this.gain = 0;
    this.targetGain = 0;
    this.sampleRate = sampleRate;
  }

  process(inputs, outputs, parameters) {
    const output = outputs[0];
    for (let channel = 0; channel < output.length; ++channel) {
      for (let i = 0; i < output[channel].length; ++i) {
        if (this.frequency > 0 && this.isActive) {
          // Простой синусоидальный синтез
          this.phase += (this.frequency / this.sampleRate) * 2 * Math.PI;
          if (this.phase > 2 * Math.PI) this.phase -= 2 * Math.PI;

          // Огибающая
          if (this.gain < this.targetGain) {
            this.gain += (1 / (this.attack * this.sampleRate));
            if (this.gain > this.targetGain) this.gain = this.targetGain;
          } else if (this.gain > 0) {
            this.gain -= (1 / (this.release * this.sampleRate));
            if (this.gain < 0) this.gain = 0;
          }

          output[channel][i] = Math.sin(this.phase) * this.gain * 0.3;
        } else {
          output[channel][i] = 0;
        }
      }
    }
    return true;
  }
}

registerProcessor('synth-processor', SynthProcessor);
2. Загрузи AudioWorklet в основном потоке
ts
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
⌄
⌄
⌄
// main.ts
async function initAudio() {
  const audioContext = new AudioContext();

  // Загружаем процессор
  await audioContext.audioWorklet.addModule('synth-processor.js');

  // Создаём 6 синтезаторов
  const synths: AudioWorkletNode[] = [];
  for (let i = 0; i < 6; i++) {
    const node = new AudioWorkletNode(audioContext, 'synth-processor');
    node.connect(audioContext.destination);
    synths.push(node);
  }

  // Управление синтезатором
  synths[0].port.postMessage({ type: 'noteOn', frequency: 440, attack: 0.01 });
  setTimeout(() => {
    synths[0].port.postMessage({ type: 'noteOff', release: 0.1 });
  }, 1000);

  return synths;
}
3. Интеграция с Tone.js
Используй Tone.js только для тайминга и управления, а звук генерируй в AudioWorklet. 
ts
1
2
3
4
5
6
7
8
⌄
const Transport = Tone.Transport;
const synths = await initAudio();

Transport.schedule((time) => {
  synths[0].port.postMessage({ type: 'noteOn', frequency: 440, when: time });
}, "+0.5");

Transport.start();
 @58<CI5AB20 B0:>3> ?>4E>40:
---------------------------------------------
| | | | |
---------------------------------------------
| | 03@C7:0 =0 main thread A=865=0 | |5=5@0F8O 72C:0 2 0C48>?>B>:5 |
---------------------------------------------
| |
 5B E@8?>2 =0 A;01KE CPU | |C48>?>B>: ?@8>@8B5B=55 JS |
---------------------------------------------
| | >;=K9 :>=B@>;L | |>6=> >?B8<878@>20BL A8=B57 ?>4 <>18;L=K5 CAB@>9AB20 |
---------------------------------------------
| | 0AHB018@C5<> | |>6=> 4>1028BL 1>;LH5 A8=B570B>@>2 |
 >?>;=8B5;L=K5 >?B8<870F88:
1. Уменьшай sampleRate, если возможно:
2. ts
3. 1
4. const audioContext = new AudioContext({ sampleRate: 22050 }); // вместо 44100
5. На некоторых устройствах это в 2 раза снижает нагрузку. 
6. Используй простые формы волн (sine, square) — они дешевле, чем wavetable.
7. Ограничь количество одновременных нот (polyphony) — 6 — это нормально, но если можно меньше — лучше.
8. Используй Tone.Offline для кэширования часто используемых звуков, если они повторяются.
9. Включи powerPreference: "low-power":
10. ts
11. 1
12. const audioContext = new AudioContext({ powerPreference: "low-power" });
❌ Почему другие подходы не работают:
* Несколько AudioContext — все равно работают в одном аудиопотоке.
* WebView — suspend при неактивности, и всё равно один общий движок.
* Веб-воркер — нет доступа к AudioContext.
 ;LB5@=0B820: Custom AudioWorklet Oscillators
Если хочешь использовать Tone.js, но вынести генерацию волн, можно создать кастомный Oscillator на основе AudioWorklet.
Смотри: Tone.js + AudioWorklet (https://github.com/Tonejs/Tone.js/issues/863)— есть примеры.
✅ Вывод
Лучшее решение — переписать часть синтеза на AudioWorklet, оставив Tone.js как дирижёра по таймингу, а звук генерировать в AudioWorkletProcessor, где он будет выполняться вне main thread. 
Это снизит нагрузку на CPU слабых телефонов, устранит хрипы, и позволит играть 6 моносинтезаторов без заиканий.
 >;57=K5 AAK;:8:
* AudioWorklet API(https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet)
* Web Audio API Performance Tips(https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Best_practices)
* Tone.js + AudioWorklet Example(https://github.com/cwilso/AudioBufferSourcePlayNote)
* Low-Latency Audio on Mobile(https://developers.google.com/web/fundamentals/media/audio-worklet)
Если хочешь, могу помочь:
* Написать рабочий шаблон синтезатора на AudioWorklet
* Сделать интеграцию с Tone.Transport
* Оптимизировать под мобильные телефоны
Напиши, какой тип синтеза ты используешь (FM, subtractive, wavetable и т.д.) — и я подскажу, как его эффективно реализовать в AudioWorklet.
subtractive

Qwen3-235B-A22B-25071:09 am
Отлично! Ты используешь subtractive synthesis — это один из самых распространённых и эффективных типов синтеза, и его можно отлично оптимизировать под AudioWorklet, особенно для слабых мобильных устройств.
Теперь я дам тебе полный рабочий пример:
* AudioWorkletProcessor с subtractive-синтезом (фильтр + огибающая + простые осцилляторы)
* Интеграция с Tone.js как дирижёром (управление таймингом)
* Оптимизация под низкую нагрузку CPU
* Поддержка 6 независимых моносинтезаторов
* Работа в реальном времени без хрипов
✅ Архитектура
1
2
3
4
5
6
7
8
Main Thread (Tone.js)
│
├── Tone.Transport → расписание нот
├── Управление: noteOn/noteOff → через port.postMessage
│
└── AudioContext
     └── 6 x AudioWorkletNode (каждый — моносинтезатор)
          └── Генерация звука в аудиопотоке (не в main thread!)
1.  subtractive-synth-processor.js (2 ?0?:5 worklets/)
js
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
⌄
⌄
⌄
⌄
⌄
⌄
⌄
⌄
⌄
// worklets/subtractive-synth-processor.js
    this.filterState += coeff * (input - this.filterState);
    return this.filterState;
  }

  // Генерация волны
  generateOsc() {
    switch (this.oscType) {
      case 'sine':
        return Math.sin(this.phase);
      case 'triangle':
        return 1 - 4 * Math.abs((this.phase / (2 * Math.PI)) - 0.5);
      case 'square':
        return this.phase < Math.PI ? 1 : -1;
      case 'sawtooth':
        return 1 - (this.phase / Math.PI);
      default:
        return Math.sin(this.phase);
    }
  }

  process(inputs, outputs, parameters) {
    const output = outputs[0];

    // Обновляем коэффициент фильтра
    this.filterCoeff = 1 - Math.exp(-2 * Math.PI * this.filterCutoff / this.sampleRate);

    for (let channel = 0; channel < output.length; ++channel) {
      for (let i = 0; i < output[channel].length; ++i) {
        let sample = 0;

        if (this.isActive && this.frequency > 0) {
          // Генерируем волну
          this.phase += (this.frequency / this.sampleRate) * 2 * Math.PI;
          if (this.phase >= 2 * Math.PI) this.phase -= 2 * Math.PI;

          sample = this.generateOsc();

          // Фильтруем
          sample = this.applyFilter(sample);

          // Огибающая
          if (this.gain < this.targetGain) {
            this.gain += 1 / (this.attack * this.sampleRate);
            if (this.gain > this.targetGain) this.gain = this.targetGain;
          } else if (this.gain > 0) {
            this.gain -= 1 / (this.release * this.sampleRate);
            if (this.gain < 0) this.gain = 0;
          }

          sample *= this.gain * 0.3; // Уменьшаем громкость
        }

        output[channel][i] = sample;
      }
    }

    // Если огибающая упала до 0, можно уведомить main thread
    if (this.gain <= 0 && this.targetGain === 0) {
      this.isActive = false;
    }

    return true;
  }
}

registerProcessor('subtractive-synth-processor', SubtractiveSynthProcessor);
2. ' 03@C7:0 8 C?@02;5=85 2 main.ts (TypeScript)
ts
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
⌄
⌄
⌄
⌄
⌄
⌄
⌄
⌄
⌄
⌄
// main.ts

import * as Tone from 'tone';

let audioContext: AudioContext;
let synths: AudioWorkletNode[] = [];

async function initAudio() {
  audioContext = new AudioContext({
    sampleRate: 44100, // можно 22050 на слабых устройствах
    latencyHint: 'interactive',
    powerPreference: 'low-power'
  });

  // Загружаем AudioWorklet
  await audioContext.audioWorklet.addModule('worklets/subtractive-synth-processor.js');

  // Создаём 6 синтезаторов
  for (let i = 0; i < 6; i++) {
    const node = new AudioWorkletNode(audioContext, 'subtractive-synth-processor');
    node.connect(audioContext.destination);
    synths.push(node);
  }

  console.log('AudioWorklet синтезаторы готовы.');
}

// Управление нотами
function playNote(synthIndex: number, midi: number, time: number) {
  const freq = Tone.Frequency(midi, 'midi').toFrequency();
  synths[synthIndex].port.postMessage({
    type: 'noteOn',
    frequency: freq,
    attack: 0.02,
    release: 0.3,
    cutoff: 1200,
    q: 1.5,
    oscType: 'sawtooth'
  });
}

function releaseNote(synthIndex: number) {
  synths[synthIndex].port.postMessage({
    type: 'noteOff',
    release: 0.3
  });
}

// Используем Tone.Transport как дирижёра
async function startMusic() {
  await initAudio();

  Tone.Transport.schedule((time) => {
    playNote(0, 60, time); // C4
  }, 0);

  Tone.Transport.schedule((time) => {
    releaseNote(0);
  }, 1);

  Tone.Transport.start();
}

startMusic();
 ?B8<870F88 4;O <>18;L=KE CAB@>9AB2
---------------------------------------------
| | | | |
---------------------------------------------
| |=sampleRate: 22050 | |new AudioContext({ sampleRate: 22050 }) 2 2 @070 <5=LH5 2KG8A;5=89 |
---------------------------------------------
| |⚙️ Упрощённый фильтр | |Мы используем one-pole LPF — быстрее, чем biquad |
---------------------------------------------
| | 3@0=8GLB5 ?>;8D>=8N | |6 3>;>A>2  =>@<0;L=>, => 5A;8 <>6=> 4  ;CGH5 |
---------------------------------------------
| | #<5=LH8 3@><:>ABL | |* 0.3 8715309 clipping 8 ?5@53@C7:8 |
---------------------------------------------
| | #25;8GLattack8release | |5=LH5 @57:8E ?5@5E>4>2  <5=LH5 aliasing 8 =03@C7:8 |
  0AH8@5=8O
* Добавь LFO в AudioWorklet (например, модуляция cutoff)
* Поддержи velocity (громкость ноты)
* Реализуй portamento (глайд)
* Добавь второй осциллятор или шум (для ричности звука)
❗ Важно: Раздача синтезаторов
Ты сказал, что у тебя 3 пула по 2 синтезатора. Отлично — просто распределяй ноты между 6 AudioWorkletNode, как обычный пул:
ts
1
2
3
4
5
6
7
⌄
let nextSynthIndex = 0;

function scheduleNote(midi: number, time: number) {
  const index = nextSynthIndex % 6;
  playNote(index, midi, time);
  nextSynthIndex++;
}
✅ Итог
Это решение:
* Работает на слабых телефонах
* Не нагружает main thread
* Снижает хрипы и заикания
* Полностью совместимо с Tone.js по таймингу
* Масштабируемо до 8+ голосов

Что делать дальше?
1. Положи subtractive-synth-processor.js в папку public/worklets/
2. Убедись, что сервер отдаёт её с правильным MIME-типом (text/javascript)
3. Запусти initAudio() при старте приложения
4. Используй Tone.Transport или Tone.Part для расписания
5. Тестируй на реальном телефоне (особенно Android с 2-4 ядрами)
Хочешь, я:
* Добавлю LFO и фильтр с резонансом?
* Сделаю кастомный Tone.js Instrument, чтобы использовать как new MySynth()?
* Добавлю поддержку velocity и sustain pedal?
Напиши — и я помогу интегрировать.
s

